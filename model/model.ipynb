{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('laptop_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Duplicated sum values:', df.duplicated().sum(), '\\n')\n",
    "print('Missing sum values:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ram'] = df['Ram'].str.replace('GB', '')\n",
    "df['Weight'] = df['Weight'].str.replace('kg', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ram'] = df['Ram'].astype('int32')\n",
    "df['Weight'] = df['Weight'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Price'], kde=True, stat='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Company'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['Company'], y=df['Price'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['TypeName'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['TypeName'], y=df['Price'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Inches'], kde=True, stat='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df['Inches'], y=df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ScreenResolution'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Touchscreen'] = df['ScreenResolution'].apply(\n",
    "    lambda x: 1 if 'Touchscreen' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Touchscreen'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['Touchscreen'], y=df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ips'] = df['ScreenResolution'].apply(lambda x: 1 if 'IPS' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['Ips'], y=df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SplitResolution = df['ScreenResolution'].str.split('x', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['X_res'] = SplitResolution[0]\n",
    "df['Y_res'] = SplitResolution[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['X_res'] = df['X_res'].str.replace(',', '').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['X_res'] = df['X_res'].astype('int')\n",
    "df['Y_res'] = df['Y_res'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ppi'] = (((df['X_res']**2) + (df['Y_res']**2))** 0.5/df['Inches']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ScreenResolution'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Inches', 'X_res', 'Y_res'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cpu'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cpu Name'] = df['Cpu'].apply(lambda x:\" \".join(x.split()[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_processor(text):\n",
    "    if text == 'Intel Core i3' or text == 'Intel Core i5' or text == 'Intel Core i7':\n",
    "        return text\n",
    "    else:\n",
    "        if text.split()[0] == 'Intel':\n",
    "            return 'Other Intel Processor'\n",
    "        else:\n",
    "            return 'AMD Processor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cpu Brand'] = df['Cpu Name'].apply(fetch_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cpu Brand'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['Cpu Brand'], y=df['Price'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Cpu', 'Cpu Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ram'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['Ram'], y=df['Price'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Memory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "if 'Memory' in df.columns:\n",
    "    df['Memory'] = df['Memory'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "    df[\"Memory\"] = df[\"Memory\"].str.replace('GB', '', regex=False)\n",
    "    df[\"Memory\"] = df[\"Memory\"].str.replace('TB', '000', regex=False)\n",
    "    new = df[\"Memory\"].str.split(\"+\", n=1, expand=True)\n",
    "    df[\"first\"] = new[0].str.strip()\n",
    "    df[\"Layer1HDD\"] = df[\"first\"].apply(lambda x: 1 if \"HDD\" in x else 0)\n",
    "    df[\"Layer1SSD\"] = df[\"first\"].apply(lambda x: 1 if \"SSD\" in x else 0)\n",
    "    df[\"Layer1Hybrid\"] = df[\"first\"].apply(lambda x: 1 if \"Hybrid\" in x else 0)\n",
    "    df[\"Layer1Flash_Storage\"] = df[\"first\"].apply(lambda x: 1 if \"Flash Storage\" in x else 0)\n",
    "    df['first'] = df['first'].str.extract(r'(\\d+)', expand=False).astype(float)\n",
    "    df[\"second\"] = new[1].fillna(\"0\").str.strip()\n",
    "    df[\"Layer2HDD\"] = df[\"second\"].apply(lambda x: 1 if \"HDD\" in x else 0)\n",
    "    df[\"Layer2SSD\"] = df[\"second\"].apply(lambda x: 1 if \"SSD\" in x else 0)\n",
    "    df[\"Layer2Hybrid\"] = df[\"second\"].apply(lambda x: 1 if \"Hybrid\" in x else 0)\n",
    "    df[\"Layer2Flash_Storage\"] = df[\"second\"].apply(lambda x: 1 if \"Flash Storage\" in x else 0)\n",
    "    df['second'] = df['second'].str.extract(r'(\\d+)', expand=False).astype(float)\n",
    "    df[\"HDD\"] = (df[\"first\"] * df[\"Layer1HDD\"] + df[\"second\"] * df[\"Layer2HDD\"]).astype(int)\n",
    "    df[\"SSD\"] = (df[\"first\"] * df[\"Layer1SSD\"] + df[\"second\"] * df[\"Layer2SSD\"]).astype(int)\n",
    "    df[\"Hybrid\"] = (df[\"first\"] * df[\"Layer1Hybrid\"] + df[\"second\"] * df[\"Layer2Hybrid\"]).astype(int)\n",
    "    df[\"Flash_Storage\"] = (df[\"first\"] * df[\"Layer1Flash_Storage\"] + df[\"second\"] * df[\"Layer2Flash_Storage\"]).astype(int)\n",
    "\n",
    "    df.drop(columns=['first', 'second', 'Layer1HDD', 'Layer1SSD', 'Layer1Hybrid', 'Layer1Flash_Storage','Layer2HDD', 'Layer2SSD', 'Layer2Hybrid', 'Layer2Flash_Storage'], inplace=True)\n",
    "else:\n",
    "    print(\"The 'Memory' column does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Memory'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Hybrid', 'Flash_Storage'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gpu'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GpuBrand'] = df['Gpu'].apply(lambda x: x.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GpuBrand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['GpuBrand'] != 'ARM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GpuBrand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['GpuBrand'], y=df['Price'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Gpu'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OpSys'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['OpSys'], y=df['Price'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizeOS(op):\n",
    "    if op == 'Windows 10' or op == 'Windows 7' or op == 'Windows 10 S':\n",
    "        return 'Windows'\n",
    "    elif op == 'macOS' or op == 'Mac OS X':\n",
    "        return 'Mac'\n",
    "    else:\n",
    "        return 'Linux/ChromeOS/Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['os'] = df['OpSys'].apply(categorizeOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['OpSys'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['os'], y=df['Price'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Weight'], kde=True, stat='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df['Weight'], y=df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.log(df['Price']), kde=True, stat='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['Price'])\n",
    "y = np.log(df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.15, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformers for specific columns\n",
    "transformers = [('col_tnf', OneHotEncoder(sparse_output=False, drop='first'), [0, 1, 7, 10, 11])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "step2 = LinearRegression()\n",
    "pipe = Pipeline([('step1', step1),('step2', step2),])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "step2 = Ridge(alpha=10)\n",
    "pipe = Pipeline([('step1', step1),('step2', step2),])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "step2 = Lasso(alpha=0.001)\n",
    "pipe = Pipeline([('step1', step1),('step2', step2),])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "step2 = KNeighborsRegressor(n_neighbors=3)\n",
    "pipe = Pipeline([('step1', step1),('step2', step2),])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "step2 = DecisionTreeRegressor(max_depth=8)\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('step2', step2),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "A powerful supervised machine learning algorithm used for classification and regression tasks. It works by finding a hyperplane in a high-dimensional space that best separates the data into different classes while maximizing the margin between the classes. SVM is effective for both linear and non-linear problems and is known for its ability to handle complex data and high-dimensional feature spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "# Create a SVM model\n",
    "step2 = SVR(kernel='rbf', C=10000, epsilon=0.1)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('step2', step2),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "An ensemble learning method that combines multiple decision trees to create a more robust and accurate predictive model. It works by constructing a forest of decision trees during training and averaging or voting on their predictions to improve the overall model's performance. Random Forest is widely used for classification and regression tasks and is known for its ability to handle high-dimensional data, reduce overfitting, and provide feature importance rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "step2 = RandomForestRegressor(n_estimators=100,\n",
    "                              random_state=3,\n",
    "                              max_samples=0.5,\n",
    "                              max_features=0.75,\n",
    "                              max_depth=15)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('step2', step2),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees\n",
    "\n",
    "Extra Trees, short for Extremely Randomized Trees, is an ensemble learning method similar to Random Forest that builds multiple decision trees. However, it differs in the way it constructs individual trees by using randomization techniques to split nodes and reduce variance. Extra Trees is known for its computational efficiency and robustness against overfitting, making it suitable for various machine learning tasks, especially when dealing with high-dimensional data or noisy datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "# Create a ExtraTrees Regressor model\n",
    "step2 = ExtraTreesRegressor(n_estimators=100,\n",
    "                            random_state=3,\n",
    "                            max_samples=0.5,\n",
    "                            max_features=0.75,\n",
    "                            max_depth=15,\n",
    "                            bootstrap=True)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('step2', step2),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boost (AdaBoost)\n",
    "An ensemble learning technique that combines multiple weak learners (typically simple models) to create a strong predictive model. It iteratively adjusts the weights of training instances, emphasizing the misclassified data points in each iteration to improve the model's performance. AdaBoost is particularly effective for binary classification problems and is known for its ability to boost the accuracy of weak models by focusing on difficult-to-classify examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "# Create a AdaBoost Regressor model\n",
    "step2 = AdaBoostRegressor(n_estimators=15, learning_rate=1.0)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('step2', step2),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient \n",
    "An ensemble learning method that builds a predictive model by combining the predictions of multiple weak models, such as decision trees, sequentially. It optimizes the model by minimizing the errors of the previous models, adjusting their weights, and adding new models in a gradient descent fashion, resulting in a strong predictive model with improved accuracy. Gradient Boosting is widely used for regression and classification tasks and is known for its robustness and capability to handle complex relationships in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "# Create a AdaBoost Regressor model\n",
    "step2 = GradientBoostingRegressor(n_estimators=500)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('step2', step2),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boost (XGBoost)\n",
    "\n",
    "A powerful and efficient machine learning algorithm that enhances the Gradient Boosting method. It is known for its speed and performance, utilizing techniques such as regularization, parallel processing, and tree pruning to optimize the boosting process. XGBoost is commonly used for a wide range of machine learning tasks, including regression, classification, and ranking, and has been a popular choice in various data science competitions and real-world applications due to its superior predictive accuracy and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "# Create a XGB Regressor model\n",
    "step2 = XGBRegressor(n_estimators=45, max_depth=5, learning_rate=0.5)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('step2', step2),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting \n",
    "An ensemble machine learning method that combines the predictions of multiple regression models to make a final prediction. It aggregates the results by averaging the individual model predictions, resulting in a more robust and accurate regression model that can benefit from the diverse strengths of the combined models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "# Define individual regression models\n",
    "rf = RandomForestRegressor(n_estimators=350, random_state=3,\n",
    "                           max_samples=0.5, max_features=0.75, max_depth=15)\n",
    "gbdt = GradientBoostingRegressor(n_estimators=100, max_features=0.5)\n",
    "xgb = XGBRegressor(n_estimators=25, learning_rate=0.3, max_depth=5)\n",
    "et = ExtraTreesRegressor(n_estimators=100, random_state=3,\n",
    "                         max_samples=0.5, max_features=0.75, max_depth=10, bootstrap=True)\n",
    "\n",
    "# Create a Voting Regressor model that combines the individual models\n",
    "# Adjusting weights for individual models in the ensemble to control their influence on the final prediction.\n",
    "step2 = VotingRegressor(\n",
    "    [('rf', rf), ('gbdt', gbdt), ('xgb', xgb), ('et', et)], weights=[5, 1, 1, 1])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('step2', step2),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "Also known as Stacked Generalization, is an ensemble learning technique that combines multiple machine learning models by training a meta-model on their predictions. It involves using a variety of base models to make predictions on the same dataset, and then a meta-model is trained on these base models' predictions to create a more powerful and accurate final model. Stacking is used to improve predictive performance and can handle complex relationships in the data by leveraging the strengths of different base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "# Define individual regression models\n",
    "rf = RandomForestRegressor(n_estimators=350, random_state=3,\n",
    "                           max_samples=0.5, max_features=0.75, max_depth=15)\n",
    "gbdt = GradientBoostingRegressor(n_estimators=100, max_features=0.5)\n",
    "xgb = XGBRegressor(n_estimators=25, learning_rate=0.3, max_depth=5)\n",
    "\n",
    "# Create a Stacking Regressor model that combines the individual models\n",
    "step2 = StackingRegressor(\n",
    "    [('rf', rf), ('gbdt', gbdt), ('xgb', xgb)], final_estimator=Ridge(alpha=100))\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('step2', step2),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R2 Score:', r2)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Model\n",
    "- Re-run the highest accuracy model again for recent R2 score\n",
    "- Finally, export the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Export the model\n",
    "pickle.dump(df,open('laptop_data.pkl','wb'))\n",
    "pickle.dump(pipe,open('pipe_object.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Customization Hypertune Parameters\n",
    "If you want hyper-tuned parameters for training machine learning models, run the following code to optimize their performance. Efficient hyperparameter tuning can significantly improve the accuracy and generalization of the models.\n",
    "\n",
    "### Random Forest Regressor Model - Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = [\n",
    "    ('col_tnf', OneHotEncoder(sparse_output=False, drop='first'), [0, 1, 7, 10, 11])\n",
    "]\n",
    "\n",
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "step2 = RandomForestRegressor()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('step2', step2),\n",
    "])\n",
    "\n",
    "# Parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'step2__n_estimators': [100, 200, 300],\n",
    "    'step2__max_depth': [10, 15, 20],\n",
    "    'step2__max_features': [0.6, 0.7, 0.8],\n",
    "}\n",
    "\n",
    "# GridSearchCV object for hyperparameter tuning\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Predictions on the test data using the tuned model\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('Best Parameters:', best_params)\n",
    "print('R2 Score:', round(r2, 2), '(', round(r2 * 100, 2), '%)')\n",
    "print('Mean Absolute Error:', round(mae, 2), '(', round(mae * 100, 2), '%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Regressor Model (Rf+Gradient) - Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "transformers = [\n",
    "    ('col_tnf', OneHotEncoder(sparse_output=False, drop='first'), [0, 1, 7, 10, 11]),\n",
    "]\n",
    "\n",
    "step1 = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "# Create an ensemble of models\n",
    "rf = RandomForestRegressor()\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "# Create a VotingRegressor model\n",
    "voting = VotingRegressor(\n",
    "    estimators=[('rf', rf), ('gb', gb)],\n",
    "    weights=[1, 1]\n",
    ")\n",
    "\n",
    "# Create a Pipeline that applies the ColumnTransformer and then the VotingRegressor model\n",
    "pipe = Pipeline([\n",
    "    ('step1', step1),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('voting', voting)\n",
    "])\n",
    "\n",
    "# Parameter grid for hyperparameter tuning\n",
    "param_dist = {\n",
    "    'voting__rf__n_estimators': [100, 200, 300],\n",
    "    'voting__rf__max_depth': [10, 15, 20],\n",
    "    'voting__rf__max_features': [0.6, 0.7, 0.8],\n",
    "    'voting__gb__n_estimators': [100, 200, 300],\n",
    "    'voting__gb__max_depth': [3, 4, 5],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipe, param_distributions=param_dist, n_iter=10, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_estimator = random_search.best_estimator_\n",
    "\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('Best Parameters:', best_params)\n",
    "print('R2 Score:', round(r2, 2), '(', round(r2 * 100, 2), '%)')\n",
    "print('Mean Absolute Error:', round(mae, 2), '(', round(mae * 100, 2), '%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Re-run the highest accuracy tuned model again and Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(df,open('laptop_data.pkl','wb'))\n",
    "\n",
    "# Export the tuned model\n",
    "with open('pipe_object.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_estimator, model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
